{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get nonAC and AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from rdkit import Chem\n",
    "from random import randint\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.AtomPairs import Pairs\n",
    "import pandas as pd\n",
    "from rdkit.Chem import DataStructs\n",
    "from Levenshtein import distance as levenshtein\n",
    "\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MakeScaffoldGeneric as GraphFramework\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import GetScaffoldForMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scaffold_compute(mol):\n",
    "    try:\n",
    "        skeleton = GraphFramework(mol)      \n",
    "    except Exception:  # In the very rare case this doesn't work, use a normal scaffold\n",
    "        skeleton = GetScaffoldForMol(mol)\n",
    "    skeleton_fp = AllChem.GetMorganFingerprintAsBitVect(skeleton, radius=2, nBits=1024)\n",
    "    return skeleton_fp\n",
    "\n",
    "\n",
    "def computesim_time(index_1, index_2):\n",
    "    mol1 = Chem.MolFromSmiles(data_smiles[index_1])\n",
    "    mol2 = Chem.MolFromSmiles(data_smiles[index_2])\n",
    "\n",
    "\n",
    "    simi_levenshtein = 1-(levenshtein(data_smiles[index_1], data_smiles[index_2]) / max(len(data_smiles[index_1]), len(data_smiles[index_2])))\n",
    "    # tanimoto similarity\n",
    "    mol1_morganFP = AllChem.GetMorganFingerprintAsBitVect(mol1, radius=2, nBits=1024)\n",
    "    mol2_morganFP = AllChem.GetMorganFingerprintAsBitVect(mol2, radius=2, nBits=1024)\n",
    "    simi_tanimoto = DataStructs.TanimotoSimilarity(mol1_morganFP, mol2_morganFP)\n",
    "    # scaffold similarity\n",
    "    mol1_scaFP = scaffold_compute(mol1)\n",
    "    mol2_scaFP = scaffold_compute(mol2)\n",
    "    simi_scaffold = DataStructs.TanimotoSimilarity(mol1_scaFP, mol2_scaFP)\n",
    "\n",
    "    # similarity\n",
    "    m_tani = simi_tanimoto >= 0.9\n",
    "    m_scaff = simi_scaffold >= 0.9\n",
    "    m_leve = simi_levenshtein >= 0.9\n",
    "    simi = int(m_tani + m_scaff + m_leve)\n",
    "    single_reult = (data_smiles[index_1], data_smiles[index_2], bioactivity[index_1], bioactivity[index_2], simi, data_ID[index_1], data_ID[index_2])\n",
    "    return single_reult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 datasets for activity cliff detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404550/404550 [00:41<00:00, 9664.77it/s] \n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data_1 = pd.read_csv('/home/xxx/anaconda3/envs/ACM/lib/python3.8/site-packages/MoleculeACE/Data/benchmark_data/CHEMBL3979_EC50.csv')\n",
    "data_1['ID'] = data_1.index\n",
    "\n",
    "data_smiles = data_1.loc[data_1['split']=='train', 'smiles'].tolist()\n",
    "bioactivity = data_1.loc[data_1['split']=='train', 'y'].tolist()\n",
    "bioactivity = np.array(bioactivity) + 9\n",
    "\n",
    "\n",
    "\n",
    "data_ID = data_1['ID'].tolist()\n",
    "\n",
    "pair_list = []\n",
    "for j in range(len(data_smiles)):\n",
    "    for k in range(j+1, len(data_smiles)):\n",
    "        pair_list.append((j, k))\n",
    "\n",
    "def compute_simi(a):\n",
    "    all_result = []\n",
    "    index_1 = a[0]\n",
    "    index_2 = a[1]\n",
    "    single_reult = computesim_time(index_1, index_2)\n",
    "    if single_reult[4] != 0:\n",
    "        return single_reult\n",
    "\n",
    "with Pool(20)as proc:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "             proc.imap_unordered(compute_simi, pair_list,\n",
    "                     ),\n",
    "            total=len(pair_list)\n",
    "        ))\n",
    "\n",
    "\n",
    "smile_1, smile_2, ki_1, ki_2, is_Simi, smile1_ID, smile2_ID = [], [], [], [], [], [], []\n",
    "for i in results:\n",
    "    try:\n",
    "        smile_1.append(i[0])\n",
    "        smile_2.append(i[1])\n",
    "        ki_1.append(i[2])\n",
    "        ki_2.append(i[3])\n",
    "        is_Simi.append(i[4])\n",
    "        smile1_ID.append(i[5])\n",
    "        smile2_ID.append(i[6])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'smile_1': smile_1,\n",
    "    'smile_2': smile_2,\n",
    "    'ki_1': ki_1,\n",
    "    'ki_2': ki_2,\n",
    "    'is_Simi': is_Simi,\n",
    "    'smile1_ID': smile1_ID,\n",
    "    'smile2_ID': smile2_ID\n",
    "})\n",
    "\n",
    "df.to_csv('./collection-1/cm3979_AC_0918.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smile_1</th>\n",
       "      <th>smile_2</th>\n",
       "      <th>ki_1</th>\n",
       "      <th>ki_2</th>\n",
       "      <th>is_Simi</th>\n",
       "      <th>smile1_ID</th>\n",
       "      <th>smile2_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>CC(C)c1onc(-c2ccccc2Cl)c1COc1ccc(COc2ccc(CC(=O...</td>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>8.397940</td>\n",
       "      <td>6.045757</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>6.045757</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(COc2ccc(C...</td>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>4.958607</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>2</td>\n",
       "      <td>898</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smile_1  \\\n",
       "1795  CC(C)c1onc(-c2ccccc2Cl)c1COc1ccc(COc2ccc(CC(=O...   \n",
       "1796  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...   \n",
       "1797  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(COc2ccc(C...   \n",
       "\n",
       "                                                smile_2      ki_1      ki_2  \\\n",
       "1795  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...  8.397940  6.045757   \n",
       "1796  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...  6.045757  6.096910   \n",
       "1797  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...  4.958607  6.096910   \n",
       "\n",
       "      is_Simi  smile1_ID  smile2_ID  \n",
       "1795        1        895        896  \n",
       "1796        1        896        899  \n",
       "1797        2        898        899  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "#读取数据\n",
    "data_frame = pd.read_csv('./collection/cm3979_AC_0918.csv')\n",
    "data_frame.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer smile_1 and smile_2 to get the second dataframe, then merge it with the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smile_1</th>\n",
       "      <th>smile_2</th>\n",
       "      <th>ki_1</th>\n",
       "      <th>ki_2</th>\n",
       "      <th>is_Simi</th>\n",
       "      <th>smile1_ID</th>\n",
       "      <th>smile2_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>CC(C)c1onc(-c2ccccc2Cl)c1COc1ccc(COc2ccc(CC(=O...</td>\n",
       "      <td>6.045757</td>\n",
       "      <td>8.397940</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>6.045757</td>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...</td>\n",
       "      <td>CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(COc2ccc(C...</td>\n",
       "      <td>6.096910</td>\n",
       "      <td>4.958607</td>\n",
       "      <td>2</td>\n",
       "      <td>899</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                smile_1  \\\n",
       "3593  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...   \n",
       "3594  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...   \n",
       "3595  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...   \n",
       "\n",
       "                                                smile_2      ki_1      ki_2  \\\n",
       "3593  CC(C)c1onc(-c2ccccc2Cl)c1COc1ccc(COc2ccc(CC(=O...  6.045757  8.397940   \n",
       "3594  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(CNc2ccc(C...  6.096910  6.045757   \n",
       "3595  CC(C)c1onc(-c2c(Cl)cccc2Cl)c1COc1ccc(COc2ccc(C...  6.096910  4.958607   \n",
       "\n",
       "      is_Simi  smile1_ID  smile2_ID  \n",
       "3593        1        896        895  \n",
       "3594        1        899        896  \n",
       "3595        2        899        898  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smi1_new = data_frame['smile_2']\n",
    "smi2_new = data_frame['smile_1']\n",
    "ki1_new = data_frame['ki_2']\n",
    "ki2_new = data_frame['ki_1']\n",
    "smi1ID_new = data_frame['smile2_ID']\n",
    "smi2ID_new = data_frame['smile1_ID']\n",
    "isSimi_new = data_frame['is_Simi']\n",
    "\n",
    "data_frame2 = pd.DataFrame({\n",
    "    'smile_1': smi1_new,\n",
    "    'smile_2': smi2_new,\n",
    "    'ki_1': ki1_new,\n",
    "    'ki_2': ki2_new,\n",
    "    'is_Simi': isSimi_new,\n",
    "    'smile1_ID': smi1ID_new,\n",
    "    'smile2_ID': smi2ID_new\n",
    "})\n",
    "\n",
    "data_frame = pd.concat([data_frame, data_frame2], ignore_index=True)\n",
    "data_frame.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## identifing AC and nonAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC(1)和nonAC(0)的数量: \n",
      " 0    2606\n",
      "1     990\n",
      "Name: is_AC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ki_1 = data_frame['ki_1'].tolist()\n",
    "ki_2 = data_frame['ki_2'].tolist()\n",
    "\n",
    "data_ki = []\n",
    "for i in range(len(ki_1)):\n",
    "    pair_ki = (ki_1[i], ki_2[i])\n",
    "    sorted_pairki = tuple(sorted(pair_ki, reverse=True))\n",
    "    data_ki.append(sorted_pairki)\n",
    "\n",
    "is_AC = []\n",
    "for a in data_ki:\n",
    "    if a[0] - a[1] <= 1:\n",
    "        is_AC.append(0)\n",
    "    else:\n",
    "        is_AC.append(1)\n",
    "\n",
    "data_frame['is_AC'] = is_AC\n",
    "count = data_frame['is_AC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 1798]\n",
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "grouped = data_frame.groupby('smile1_ID').groups\n",
    "group_smiindex = [list(grouped[key]) for key in grouped.keys()]\n",
    "print(group_smiindex[1])\n",
    "\n",
    "group_Ki = []\n",
    "for i in group_smiindex:\n",
    "    group_Ki.append([data_frame['is_AC'][j] for j in i])\n",
    "print(group_Ki[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "group_smi1 = []\n",
    "group_smi1_ki = []\n",
    "group_smi1num = []\n",
    "pki_anchor = []\n",
    "\n",
    "for i in group_smiindex:\n",
    "    group_smi1.append(data_frame['smile_1'][i[0]])\n",
    "    group_smi1num.append(data_frame['smile1_ID'][i[0]])\n",
    "    group_smi1_ki.append(data_frame['ki_1'][i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor的ID: 5\n",
      "anchor的SMILES: CCCC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2)c1)C(=O)O\n",
      "与anchor相似的smiles: ['CCC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2F)c1)C(=O)O', 'CCCC(Cc1ccc(OC)c(CNC(=O)c2ccc(C(F)(F)F)cc2F)c1)C(=O)O', 'CCCCC(Cc1ccc(OC)c(CNC(=O)c2ccc(C(F)(F)F)cc2)c1)C(=O)O', 'CCC(Cc1ccc(OC)c(C(=O)NCCc2ccc(C(F)(F)F)cc2)c1)C(=O)O', 'CCC(Cc1ccc(OC)c(C(=O)NCc2ccc(OC(F)(F)F)cc2)c1)C(=O)O', 'CCOC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2)c1)C(=O)O']\n",
      "这些SMILES与anchor的pki差值: [0.3802112417116099, 1.77815125038365, 0.5351132016973503, 0.20411998265593034, 0.42596873227229004, 0.09691001300805002]\n"
     ]
    }
   ],
   "source": [
    "group_smi2 = []\n",
    "group_smi2_pki = []\n",
    "for i in group_smiindex:\n",
    "    group_smi2.append([data_frame['smile_2'][j] for j in i])\n",
    "    group_smi2_pki.append([data_frame['ki_2'][j] for j in i])\n",
    "\n",
    "delta_pki = []\n",
    "for i in group_smiindex:\n",
    "    pki_smi2 = [data_frame['ki_2'][j] for j in i]\n",
    "    delta_pki.append([abs(-x + data_frame['ki_1'][i[0]]) for x in pki_smi2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anchor_smi': 'CCC(Cc1ccc(OC)c(C(=O)NCc2ccc(OC(F)(F)F)cc2)c1)C(=O)O', 'delta_nonAC': [0.5228787452803401, 0.42596873227229004, 0.045757490560680125, 0.2218487496163597], 'delta_AC': [], 'smile_nonAC': ['CCOC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2)c1)C(=O)O', 'CCCC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2)c1)C(=O)O', 'CCC(Cc1ccc(OC)c(C(=O)NCc2ccc(C(F)(F)F)cc2F)c1)C(=O)O', 'CCC(Cc1ccc(OC)c(C(=O)NCCc2ccc(C(F)(F)F)cc2)c1)C(=O)O'], 'smile_AC': [], 'nonAC_pki': [5.52287874528034, 5.61978875828839, 6.0, 5.82390874094432], 'AC_pki': []}\n"
     ]
    }
   ],
   "source": [
    "save_SI = []\n",
    "for j in range(len(group_Ki)):\n",
    "    d = {}\n",
    "    d['anchor_smi'] = group_smi1[j]\n",
    "    d['delta_nonAC'] = []\n",
    "    d['delta_AC'] = []\n",
    "    d['smile_nonAC'] = []\n",
    "    d['smile_AC'] = []\n",
    "    d['nonAC_pki'] = []\n",
    "    d['AC_pki'] = []\n",
    "\n",
    "    for i, x in enumerate(delta_pki[j]):\n",
    "        if x <= 1:\n",
    "            d['delta_nonAC'].append(x)\n",
    "            d['smile_nonAC'].append(group_smi2[j][i])\n",
    "            d['nonAC_pki'].append(group_smi2_pki[j][i])\n",
    "        else:\n",
    "            d['delta_AC'].append(x)\n",
    "            d['smile_AC'].append(group_smi2[j][i])\n",
    "            d['AC_pki'].append(group_smi2_pki[j][i])\n",
    "    save_SI.append(d)\n",
    "print(save_SI[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as binary format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(save_SI)\n",
    "df['anchor_ki'] = group_smi1_ki\n",
    "df.columns = df.columns.map(str)\n",
    "# Save DataFrame to Parquet file\n",
    "df.to_parquet('./collection-1/cm3979_AC_0918.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "df_0715 = pq.read_table('./collection/cm239_AC_0918.parquet').to_pandas()\n",
    "# df_0715.tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
